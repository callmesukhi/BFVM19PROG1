{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/callmesukhi/BFVM19PROG1/blob/main/assessments/Assignment_week_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7y9NCiYwo8w9"
   },
   "source": [
    "# Week 04 Assignment weather data\n",
    "\n",
    "Welcome to week four of this course programming 1. You will to organise your data into the required format and apply smoothing. In this assignment we will work with weatherdata from the KNMI. A subset of weatherdata is for you available in the file: `KNMI_20181231.csv`. The data consist of several stations with daily weather data of several years. Your task is to make a plot similar to the plot below.\n",
    "\n",
    "\n",
    "<img src=\"https://github.com/callmesukhi/BFVM19PROG1/blob/main/assessments/images/weather.png?raw=1\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "\n",
    "Furthermore the plot needs the following enhancements\n",
    "\n",
    "1. proper titles and ticks\n",
    "2. a slider widget selecting a particular year or all years\n",
    "3. lines need to be smoothed\n",
    "3. legends needs to be added\n",
    "\n",
    "Use your creativity. Consider colors, alpha settings, sizes etc. \n",
    "\n",
    "Learning outcomes\n",
    "\n",
    "- load, inspect and clean a dataset \n",
    "- reformat dataframes\n",
    "- apply smoothing technologies\n",
    "- visualize timeseries data\n",
    "\n",
    "The assignment consists of 6 parts:\n",
    "\n",
    "- [part 1: load the data](#0)\n",
    "- [part 2: clean the data](#1)\n",
    "- [part 3: reformat data](#2)\n",
    "- [part 4: smooth the data](#3)\n",
    "- [part 5: visualize the data](#4)\n",
    "- [part 6: Challenge](#5)\n",
    "\n",
    "Part 1 and 5 are mandatory, part 6 is optional (bonus)\n",
    "To pass the assingnment you need to a score of 60%. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-h-aFp4o8xE"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENflWKtzo8xG"
   },
   "source": [
    "<a name='0'></a>\n",
    "## Part 1: Load the data\n",
    "\n",
    "Either load the dataset `KNMI_20181231.csv` or `KNMI_20181231.txt.tsv`. The dataheaders contain spaces and are not very self explainable. Change this into more readable ones. Select data from station 270. Select only the mean, minimum and maximum temperature. The data should look something like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U1T8npcRs9U0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "oXgnzoj0tXWf",
    "outputId": "cc0f8877-666d-4e55-d3fe-9ca3a3f6c378"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\callm\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (0,2,3,4,5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>Tmean</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>Tmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97642</th>\n",
       "      <td>270</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>42</td>\n",
       "      <td>-4</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97643</th>\n",
       "      <td>270</td>\n",
       "      <td>2000-01-02</td>\n",
       "      <td>55</td>\n",
       "      <td>33</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97644</th>\n",
       "      <td>270</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>74</td>\n",
       "      <td>49</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97645</th>\n",
       "      <td>270</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97646</th>\n",
       "      <td>270</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>41</td>\n",
       "      <td>14</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      STATION       DATE  Tmean   Tmin   Tmax\n",
       "97642     270 2000-01-01     42     -4     79\n",
       "97643     270 2000-01-02     55     33     74\n",
       "97644     270 2000-01-03     74     49     89\n",
       "97645     270 2000-01-04     46     22     75\n",
       "97646     270 2000-01-05     41     14     56"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('KNMI_20181231.txt.tsv', sep=',', skiprows=63, parse_dates=['YYYYMMDD'])\n",
    "df = df.drop(df.index[0])\n",
    "df.rename(columns={\"# STN\":\"STATION\", \"YYYYMMDD\":\"DATE\", \"   TG\":\"Tmean\", \"   TN\":\"Tmin\", \"   TX\":\"Tmax\"}, inplace=True)\n",
    "df = df.drop(['   SQ', '   DR', '   RH'], axis='columns')\n",
    "df_270 = df[df.STATION == 270]\n",
    "df_270.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8p_eJOYiaYcg",
    "outputId": "aabf988f-10e2-4230-987f-5578567a1cef"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/KNMI_20181231.txt.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-51ae74dd2898>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/KNMI_20181231.txt.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m63\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"# STN\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"STATION\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"YYYYMMDD\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"DATE\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"   TG\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"Tmean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"   TN\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"Tmin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"   TX\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"Tmax\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'   SQ'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'   DR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'   RH'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'columns'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'^\\s*$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\callm\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\callm\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\callm\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\callm\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\callm\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/KNMI_20181231.txt.tsv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/content/KNMI_20181231.txt.tsv', sep=',', skiprows=63)\n",
    "df = df.drop(df.index[0])\n",
    "df.rename(columns={\"# STN\":\"STATION\", \"YYYYMMDD\":\"DATE\", \"   TG\":\"Tmean\", \"   TN\":\"Tmin\", \"   TX\":\"Tmax\"}, inplace=True)\n",
    "df = df.drop(['   SQ', '   DR', '   RH'], axis='columns')\n",
    "df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "df.isna().sum()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bw2AIRt3bbCi",
    "outputId": "07ef2c32-127c-4cf7-921d-2b5566bdc5c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 331316 entries, 1 to 331316\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype         \n",
      "---  ------   --------------   -----         \n",
      " 0   STATION  331316 non-null  int64         \n",
      " 1   DATE     331316 non-null  datetime64[ns]\n",
      " 2   Tmean    237566 non-null  float64       \n",
      " 3   Tmin     237567 non-null  float64       \n",
      " 4   Tmax     237567 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1)\n",
      "memory usage: 15.2 MB\n"
     ]
    }
   ],
   "source": [
    "df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')\n",
    "df['STATION'] = pd.to_numeric(df['STATION'], errors='coerce').astype('int')\n",
    "df['Tmean'] = pd.to_numeric(df['Tmean'], errors='coerce')\n",
    "df['Tmin'] = pd.to_numeric(df['Tmin'], errors='coerce')\n",
    "df['Tmax'] = pd.to_numeric(df['Tmax'], errors='coerce')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdBXKKKibkfm",
    "outputId": "69f915d5-8394-4485-851b-96201e0fe155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6940 entries, 97642 to 104581\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   STATION  6940 non-null   int64         \n",
      " 1   DATE     6940 non-null   datetime64[ns]\n",
      " 2   Tmean    6940 non-null   float64       \n",
      " 3   Tmin     6940 non-null   float64       \n",
      " 4   Tmax     6940 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1)\n",
      "memory usage: 325.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_270 = df[df.STATION == 270]\n",
    "df_270.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhyWB-sLo8xH"
   },
   "source": [
    "        station      Date  Tmean   Tmin   Tmax\n",
    "245205      270  19510101      0    -40     24\n",
    "245206      270  19510102      9     -5     19\n",
    "245207      270  19510103      5     -8     17\n",
    "245208      270  19510104      5    -15     17\n",
    "245209      270  19510105     26      6     46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GF4iS5IjS08o",
    "outputId": "493b9316-a33c-4688-ede5-408ce14e7528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6940 entries, 97642 to 104581\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   STATION  6940 non-null   object        \n",
      " 1   DATE     6940 non-null   datetime64[ns]\n",
      " 2   Tmean    6940 non-null   object        \n",
      " 3   Tmin     6940 non-null   object        \n",
      " 4   Tmax     6940 non-null   object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 325.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_270.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wV0DgLjuo8xJ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFb1aTPoJCw8"
   },
   "source": [
    "# temp range for few years\n",
    "# min of each month temp for one particular year\n",
    "# max of each \n",
    "# average temp of each day \n",
    "# user slider for smoothing \n",
    "# user slider for selecting different years "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWv_uXZJo8xL"
   },
   "source": [
    "<a name='1'></a>\n",
    "## Part 2: Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MELtnCcyo8xM"
   },
   "source": [
    "The data ia not clean. There are empty cells in the dataframe which needs to be replaced with NaN's and the temperature is in centidegrees which needs to be transformed into degrees. The date field needs a datetime format. For visualization convience we would like to remove the leap year. Conduct the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urx1YB5Po8xN",
    "outputId": "a90e7287-77fa-447c-8203-1a725a460e60",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION    0\n",
       "DATE       0\n",
       "Tmean      0\n",
       "Tmin       0\n",
       "Tmax       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace cells with spaces to NaN\n",
    "df_270 = df_270.replace(r'^\\s*$', np.nan, regex=True)\n",
    "# df_270 = df_270.applymap(lambda x: np.nan if isinstance(x, basestring) and x.isspace() else x)\n",
    "# df_270 = df_270.replace(r'', np.NaN)\n",
    "df_270.isna().sum()\n",
    "# #change data formats\n",
    "df_270['DATE'] = pd.to_datetime(df_270['DATE'], errors='coerce')\n",
    "df_270['STATION'] = pd.to_numeric(df_270['STATION'], errors='coerce').astype('int')\n",
    "df_270['Tmean'] = pd.to_numeric(df_270['Tmean'], errors='coerce')\n",
    "df_270['Tmin'] = pd.to_numeric(df_270['Tmin'], errors='coerce')\n",
    "df_270['Tmax'] = pd.to_numeric(df_270['Tmax'], errors='coerce')\n",
    "# # df_270['STATION'] = pd.to_numeric(df_270.STATION, errors='coerce')\n",
    "# #change temperatures to celcius degrees\n",
    "# #remove leap \n",
    "# df_270.info()\n",
    "df_270.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snHGtTobo8xO"
   },
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<ul><li>pd.to_datetime(df['Date'].astype(str), format='%Y%m%d')</li>\n",
    "    <li>regex for empty cells = `^\\s*$` </li>\n",
    "    <li>remove month == 2 & day == 29</li> \n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tc7ilMb3o8xP",
    "outputId": "b0eff8e8-4b10-4dd8-e0e1-9461176366f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6940 entries, 97642 to 104581\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   STATION  6940 non-null   int64         \n",
      " 1   DATE     6940 non-null   datetime64[ns]\n",
      " 2   Tmean    0 non-null      float64       \n",
      " 3   Tmin     0 non-null      float64       \n",
      " 4   Tmax     0 non-null      float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1)\n",
      "memory usage: 325.3 KB\n"
     ]
    }
   ],
   "source": [
    "#Test your outcome\n",
    "df_270.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXN5pXpTo8xQ"
   },
   "source": [
    "### Expected outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bCI0gJHo8xR"
   },
   "source": [
    "DatetimeIndex: 24820 entries, 1951-01-01 to 2018-12-31\n",
    "Data columns (total 5 columns):\n",
    " #   Column   Non-Null Count  Dtype         \n",
    "---  ------   --------------  -----         \n",
    " 0   station  24820 non-null  int64         \n",
    " 1   Date     24820 non-null  datetime64[ns]\n",
    " 2   Tmean    24819 non-null  float64       \n",
    " 3   Tmin     24819 non-null  float64       \n",
    " 4   Tmax     24819 non-null  float64       \n",
    "dtypes: datetime64[ns](1), float64(3), int64(1)\n",
    "memory usage: 1.1 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v15DIkXo8xS"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0FmqqfWo8xT"
   },
   "source": [
    "<a name='2'></a>\n",
    "## Part 3: Reform your data\n",
    "\n",
    "First we will split the data in data from 2018 and data before 2018. Best is to split this in two dataframes. \n",
    "Next we need for the non 2018 data the minimum values for each day and the maximum values for each day. So we look for the minimum value out of all january-01 minimum values (regardless the year). Create a dataframe with 365 days containing the ultimate minimum and the ultimate maximum per day. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LH2B7Pgzo8xU"
   },
   "outputs": [],
   "source": [
    "def month_day(df_multipleyears):\n",
    "    #your code to reform data here\n",
    "    \n",
    "    print(df_groupedbymonthday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCw0F4kFo8xU"
   },
   "outputs": [],
   "source": [
    "#Test your code\n",
    "def test_reformed(df)\n",
    "    #\n",
    "    df = df[(df.index.year > 2007) & (df.index.year < 2018)]\n",
    "    month_day(df)\n",
    "\n",
    "test_reformed(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrsQJWiyo8xV"
   },
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<ul><li>use the dt.month and dt.day to groupby</li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_166MRGo8xW"
   },
   "source": [
    "### Expected outcome\n",
    "Note, the layout or names my differ, but the length should be 365 and the minimum values should be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0z5eg8co8xW"
   },
   "source": [
    "month  day\n",
    "1      1      -5.8\n",
    "       2      -7.5\n",
    "       3     -12.6\n",
    "       4      -4.1\n",
    "       5      -6.0\n",
    "              ... \n",
    "12     27     -4.8\n",
    "       28     -4.2\n",
    "       29     -6.7\n",
    "       30    -10.2\n",
    "       31    -10.6\n",
    "Name: Tmin, Length: 365, dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVus0QOqo8xX"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmKWsZUso8xZ"
   },
   "source": [
    "<a name='3'></a>\n",
    "## Part 4: Smooth the data\n",
    "\n",
    "Make a function that takes an array or a dataframe column and returns an array of smoothed data. Explain in words why you choose a certain smoothing algoritm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nC0W3eXvo8xa"
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "#your motivation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWedUjJoo8xc"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4_S1JdCo8xd"
   },
   "source": [
    "<a name='4'></a>\n",
    "## Part 5: Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tTPKz5Ho8xe"
   },
   "source": [
    "Plot the mean temperature of the year 2018. Create a shaded band with the ultimate minimum values and the ultimate maximum values from the multi-year dataset. Add labels, titles and legends. Use proper ranges. Be creative to make the plot attractive. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFz8Ve8Eo8xf"
   },
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<ul><li>use from bokeh.models import Band</li>\n",
    "    <li>use ColumnDataSource to parse data arrays</li>\n",
    "    <li>look for xaxis tick formatters</li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oNy6nYCo8xh"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXeZM7Pko8xi"
   },
   "source": [
    "<a name='5'></a>\n",
    "## Part 6: Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn7ob0Sxo8xj"
   },
   "source": [
    "Make a widget in which you can select the year range for the multiyear set. Add this to your layout to make the plot interactive. Add another widget to select or deselect the smoother. Inspiration: https://demo.bokeh.org/weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpuiChlTo8xk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Assignment_week_04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
